# Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data

## Title

Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data

## Metadata

- **paper_id**: `2510.14831`
- **arXiv_abs**: https://arxiv.org/abs/2510.14831
- **arXiv_pdf**: https://arxiv.org/pdf/2510.14831.pdf
- **authors**: Qi Chen, Xinze Zhou, Chen Liu, Hao Chen, Wenxuan Li, Zekun Jiang, Ziyan Huang, Yuxuan Zhao, Dexin Yu, Junjun He, Yefeng Zheng, Ling Shao, Alan Yuille, Zongwei Zhou
- **categories**: cs.CV
- **created**: `2025-10-16T16:08:09+00:00`
- **updated**: `2025-11-02T16:13:33+00:00`
- **datestamp**: `2025-11-04`
- **setspecs**: cs:cs:CV
- **exported_at**: `2026-01-24T01:01:20.758522+00:00`

## Abstract

AI for tumor segmentation is limited by the lack of large, voxel-wise annotated datasets, which are hard to create and require medical experts. In our proprietary JHH dataset of 3,000 annotated pancreatic tumor scans, we found that AI performance stopped improving after 1,500 scans. With synthetic data, we reached the same performance using only 500 real scans. This finding suggests that synthetic data can steepen data scaling laws, enabling more efficient model training than real data alone. Motivated by these lessons, we created AbdomenAtlas 2.0--a dataset of 10,135 CT scans with a total of 15,130 tumor instances per-voxel manually annotated in six organs (pancreas, liver, kidney, colon, esophagus, and uterus) and 5,893 control scans. Annotated by 23 expert radiologists, it is several orders of magnitude larger than existing public tumor datasets. While we continue expanding the dataset, the current version of AbdomenAtlas 2.0 already provides a strong foundation--based on lessons from the JHH dataset--for training AI to segment tumors in six organs. It achieves notable improvements over public datasets, with a +7% DSC gain on in-distribution tests and +16% on out-of-distribution tests.
