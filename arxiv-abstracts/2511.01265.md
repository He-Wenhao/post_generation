# AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs

## Title

AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs

## Metadata

- **paper_id**: `2511.01265`
- **arXiv_abs**: https://arxiv.org/abs/2511.01265
- **arXiv_pdf**: https://arxiv.org/pdf/2511.01265.pdf
- **authors**: Mo El-Haj, Paul Rayson
- **categories**: cs.CL
- **created**: `2025-11-03T06:30:31+00:00`
- **updated**: `2025-11-25T03:27:09+00:00`
- **datestamp**: `2025-11-26`
- **journal_ref**: IEEE BigData 2025
- **setspecs**: cs:cs:CL
- **exported_at**: `2026-01-24T01:01:20.762380+00:00`

## Abstract

We introduce AraFinNews, the largest publicly available Arabic financial news dataset to date, comprising 212,500 article-headline pairs spanning a decade of reporting from 2015 to 2025. Designed as an Arabic counterpart to major English summarisation corpora such as CNN/DailyMail, AraFinNews provides a realistic benchmark for evaluating domain-specific language understanding and generation in financial contexts. Using this resource, we investigate the impact of domain specificity on abstractive summarisation of Arabic financial texts with large language models (LLMs). In particular, we evaluate transformer-based models: mT5, AraT5, and the domain-adapted FinAraT5 to examine how financial-domain pretraining influences accuracy, numerical reliability, and stylistic alignment with professional reporting. Experimental results show that domain-adapted models generate more coherent summaries, especially in their handling of quantitative and entity-centric information. These findings highlight the importance of domain-specific adaptation for improving narrative fluency in Arabic financial summarisation. The dataset is freely available for non-commercial research at https://github.com/ArabicNLP-uk/AraFinNews.
