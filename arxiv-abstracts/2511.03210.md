# Adaptive directional decomposition methods for nonconvex constrained optimization

## Title

Adaptive directional decomposition methods for nonconvex constrained optimization

## Metadata

- **paper_id**: `2511.03210`
- **arXiv_abs**: https://arxiv.org/abs/2511.03210
- **arXiv_pdf**: https://arxiv.org/pdf/2511.03210.pdf
- **authors**: Qiankun Shi, Xiao Wang
- **categories**: math.OC
- **created**: `2025-11-05T05:54:52+00:00`
- **updated**: `2025-11-07T07:52:07+00:00`
- **datestamp**: `2025-11-10`
- **setspecs**: math:math:OC
- **exported_at**: `2026-01-24T01:01:20.763390+00:00`

## Abstract

In this paper, we study nonconvex constrained optimization problems with both equality and inequality constraints, covering deterministic and stochastic settings. We propose a novel first-order algorithm framework that employs a decomposition strategy to balance objective reduction and constraint satisfaction, together with adaptive update of stepsizes and merit parameters. Under certain conditions, the proposed adaptive directional decomposition methods attain an iteration complexity of order \(O(\epsilon^{-2})\) for finding an \(\epsilon\)-KKT point in the deterministic setting. In the stochastic setting, we further develop stochastic variants of approaches and analyze their theoretical properties by leveraging the perturbation theory. We establish the high-probability oracle complexity to find an $\epsilon$-KKT point of order \( \tilde O(\epsilon^{-4}, \epsilon^{-6}) \) (resp. \(\tilde O(\epsilon^{-3}, \epsilon^{-5}) \)) for gradient and constraint evaluations, in the absence (resp. presence) of sample-wise smoothness. To the best of our knowledge, the obtained complexity bounds are comparable to, or improve upon, the state-of-the-art results in the literature.
